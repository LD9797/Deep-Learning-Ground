{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\python38\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\python38\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python38\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python38\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python38\\lib\\site-packages (from scikit-learn) (1.9.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#taken from https://pythonprogramminglanguage.com/logistic-regression-spam-filter/\n",
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model._logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#load dataset\n",
    "dataset_frame = pd.read_csv('SMSSpamCollection', delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will Ã¼ b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n",
      "Labels\n",
      "0        ham\n",
      "1        ham\n",
      "2       spam\n",
      "3        ham\n",
      "4        ham\n",
      "        ... \n",
      "5567    spam\n",
      "5568     ham\n",
      "5569     ham\n",
      "5570     ham\n",
      "5571     ham\n",
      "Name: 0, Length: 5572, dtype: object\n",
      "Shape for train data  (3343,)\n",
      "Shape for test data  (2229,)\n",
      "Vectorized training data\n",
      "  (0, 5444)\t0.4366212710290617\n",
      "  (0, 2905)\t0.32279130689544705\n",
      "  (0, 2566)\t0.3908085661565827\n",
      "  (0, 4820)\t0.4137149185928222\n",
      "  (0, 5445)\t0.4366212710290617\n",
      "  (0, 4592)\t0.4366212710290617\n",
      "  (1, 1067)\t0.49365234969678357\n",
      "  (1, 3132)\t0.23544190899582706\n",
      "  (1, 870)\t0.2819129414840383\n",
      "  (1, 5872)\t0.391444117922322\n",
      "  (1, 2705)\t0.46944206692161955\n",
      "  (1, 5840)\t0.4977903242324375\n",
      "  (2, 2952)\t0.4047160768997432\n",
      "  (2, 5962)\t0.18456294181680796\n",
      "  (2, 4865)\t0.6241930706909109\n",
      "  (2, 4004)\t0.26490803574564054\n",
      "  (2, 1691)\t0.5851052560912822\n",
      "  (3, 5984)\t0.2943925737161623\n",
      "  (3, 4288)\t0.4055128880406924\n",
      "  (3, 6469)\t0.21772188193546468\n",
      "  (3, 5432)\t0.3142069660906943\n",
      "  (3, 1614)\t0.49789453124217775\n",
      "  (3, 3097)\t0.21744543892516568\n",
      "  (3, 1322)\t0.3526994872051127\n",
      "  (3, 771)\t0.24800235499743328\n",
      "  :\t:\n",
      "  (3339, 6361)\t0.2778085118044729\n",
      "  (3339, 1088)\t0.3534778269463013\n",
      "  (3339, 5170)\t0.2909720708503215\n",
      "  (3339, 3958)\t0.2722528181597973\n",
      "  (3339, 4818)\t0.2778085118044729\n",
      "  (3340, 3060)\t0.3340646917053984\n",
      "  (3340, 6496)\t0.3340646917053984\n",
      "  (3340, 1692)\t0.3340646917053984\n",
      "  (3340, 4048)\t0.3179811981932977\n",
      "  (3340, 3708)\t0.3179811981932977\n",
      "  (3340, 5912)\t0.2977183927351685\n",
      "  (3340, 2392)\t0.25687671022040964\n",
      "  (3340, 4566)\t0.2744027909178831\n",
      "  (3340, 2957)\t0.21056157818433935\n",
      "  (3340, 3248)\t0.3357491932843118\n",
      "  (3340, 4137)\t0.14037968287884198\n",
      "  (3340, 5850)\t0.10619475453453703\n",
      "  (3340, 2952)\t0.19303549748686583\n",
      "  (3340, 5962)\t0.0880301063505135\n",
      "  (3341, 6652)\t0.8302020312239512\n",
      "  (3341, 4213)\t0.5574626331438057\n",
      "  (3342, 1106)\t0.5893141587676289\n",
      "  (3342, 1662)\t0.6534340738539203\n",
      "  (3342, 754)\t0.39511252639983024\n",
      "  (3342, 5850)\t0.2638537945238136\n",
      "['ham' 'spam']\n",
      "Vectorized test\n",
      "Accuracy test  0.9676936883039187\n"
     ]
    }
   ],
   "source": [
    "#data is in dataset_frame[1]\n",
    "#labels are in dataset_frame[0] \n",
    "print(\"Data\")\n",
    "print(dataset_frame[1])\n",
    "print(\"Labels\")\n",
    "#the labels are ham and spam\n",
    "print(dataset_frame[0])\n",
    "#Split the data, with 25% of testing by default\n",
    "#PREPROCESS DATASET!\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(dataset_frame[1], dataset_frame[0], test_size=0.4)\n",
    "print(\"Shape for train data \", X_train_raw.shape)\n",
    "print(\"Shape for test data \", X_test_raw.shape)\n",
    "vectorizer = TfidfVectorizer()\n",
    "#Sparse representation of the data (matrix_index, value) for each term\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "print(\"Vectorized training data\")\n",
    "print(X_train)\n",
    "#Train logistic regression model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "#Test example\n",
    "X_test = vectorizer.transform( ['Hey how are you?', 'URGENT! Your Mobile No 1234 was awarded a Prize'] )\n",
    "predictions = classifier.predict(X_test)\n",
    "print(predictions)\n",
    "#Test metrics\n",
    "X_test = vectorizer.fit_transform(X_train_raw)\n",
    "predictions_test = classifier.predict(X_test)\n",
    "print(\"Vectorized test\")\n",
    "accuracy_test =  accuracy_score(y_train, predictions_test)\n",
    "print(\"Accuracy test \", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
